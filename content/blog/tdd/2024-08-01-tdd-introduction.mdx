---
title: 测试驱动开发
date: '2024-08-01'
tags:
  - extreme programming
  - tdd
published: true
brief: >-
  自动化测试是软件交付质量的保障，能显著提升问题发现和定位的速度。测试金字塔和敏捷测试四象限为制定测试策略提供了理论指导。Q1定位测试聚焦细粒度代码，帮助快速定位问题；Q2发现测试覆盖业务功能，帮助快速发现问题。合理搭配不同层次的测试，构建自动化测试体系，是实现高质量软件交付的关键实践。
---

## 初探软件测试

> 在规定的条件下对程序进行操作，以发现程序错误，衡量软件质量，并对其是否能满足设计要求
>
> 进行评估的过程。

袁帅边默念着这句关于软件测试的经典定义，边打开Android Studio。那到底如何做软件测试？他想到了最近自己做过的两个小场景。

场景1：袁帅开发了一个任务管理系统，他模拟用户的行为在界面输入正确的用户名和密码，点击登陆后能够登陆到系统的主界面，并看到自己的任务清单。

![](/images/tdd/tdd-user-scenario.webp)

场景2，袁帅编写了一个统计字符的函数后，他会模拟调用者传入一个特定的字符串，看它执行后能否返回你预期的结果。

![](/images/tdd/tdd-char-count.webp)

在上述两个例子中，袁帅对自己开发的系统和函数提前进行测试，看看能否发现Bug。他心里很清楚，这么做就是想最大限度地确保软件交付给用户时功能是正确的 -- 小心驶得万年船。**交付高质量有价值的软件是他在Thoughtworks做程序员意义之一**。

没有人希望Bug被真实用户发现，开发团队要尽可能降低错误流入生产的概率，越早越好，因为发现问题的时机越早，修复的成本越低。所以，及时**发现软件问题**成为了一个关键的因素。

及时发现问题，让问题尽早暴露，可是团队无法有效快速的定位问题，难免镜中赏花不知花在哪。所以，**快速定位问题**成了另一个关键因素。定位到问题方可有的放矢，相比于修复问题，定位问题要花更多时间。

**就这样，袁帅将发现问题的速度**和**定位问题的速度**作为自己和团队的修炼目标。而要实现两个速度的稳定持续提升，就需要引入必要的自动化。传统绿皮火车靠人工烧煤，速度怎么也快不起来，而配备了全车动力系统的高铁让铁路出行更加顺溜。

**经常做高铁出差的袁帅，索性将自动化测试比喻成软件测试中的高铁。**

针对自动化测试，Wiki给了如下定义：

> 在软件测试中，**自动化测试**指的是使用独立于待测软件的其他软件来自动执行测试、比较实际结果与预期并生成测试报告这一过程。在测试流程已经确定后，测试自动化可以自动执行的一些重复但必要测试工作。也可以完成手动测试几乎不可能完成的测试。

说白了，就是让机器代替人来执行那些手工的测试过程。**在敏捷软件开发中，自动化测试是不可或缺的工程实践。**

## 唯快不破的价值

**假如不做自动化测试会怎么样？**

在开发过程中，无论是新增功能还是修复缺陷都需要大量的回归测试。如果仅靠"人肉"战术，一方面测试人员要对付新功能的测试，另一方面又要回归已有功能。人毕竟不是机器，大量的鼠标点击也不像打地鼠那么有趣，在经过重复枯燥地点击后，难免会滋生"审丑"疲劳，而软件的"丑"有时就被熟视无睹了。

就拿敏捷迭代开发来说，在固定长度的迭代周期内，第一个迭代开发了3块功能并进行了测试，第二个迭代新开发了3块功能，除了测试新功能，还要回归迭代一的功能，而到第三个迭代要回归测试的功能就更多。此时多半有两种选择：

+ 方式一：一种是减少新功能开发，大家都来做手工回归测试，这样才有可能完成，但项目进度会受到严重影响。
+ 方式二：另一种选择是新功能照常开发，留给回归测试的时间被挤压，而测试人员不得不把重点放在新功能上面，回归测试就会因为时间紧被简化甚至漏化了。简化的后果就是原来应该被回归的范围缩小，从而导致越来越多的缺陷被遗漏掉。

![](/images/tdd/tdd-regression-cost.webp)

在大多数实际项目交付中，为了完成项目目标，袁帅见过很多团队选择了方式二，从此生产事故率开始上升，即便有幸没上生产，返工的频率也肉眼提高，而且返工的时机越晚，修复的成本大大提升。增加的修复成本，反噬了团队的宝贵资源，陷入恶性增长循环。

一些项目会琢磨着加班和加人（QA），这么做只是扬汤止沸。

**如何避免这种问题？**

**一种方式是一做就对，另一种方式是出手够快**。前者已经被证实不可能，后者努把力还有点戏。袁帅一直都承认软件开发难免存在缺陷，但是只要能够足够快搞定问题（发现 -> 定位 -> 修复），交付效率（质量 + 速度）也可得到保证。

> 解决问题的最好的态度是勇敢面对问题，在它还没有产生较大负面影响的时候就揪出来并干掉。
>
> -- 老马可能说过

在有限的交付时间内，要想从容面对缺陷营造的惊喜，就要采用一种更高效、更快的方式来代替手工测试。自动化测试无疑是当下的一个优秀的工程实践，它规避了人类固有的审丑疲劳，同时节省了大量手工工作，让回归更全面也更靠谱。

在袁帅看来，自动化测试本质上是实现软件测试的提速，提升了两个核心速度：

**发现问题的速度：**

1. 发现的时机要早。这就要求测试前移，开发人员也要编写自动化测试。
2. 发现的速度要快。这就要求编写有效的、执行效率高的自动化测试。

**定位问题的速度：**

1. 定位的精准要够。这就要良好的测试策略，划分合适的测试粒度。
2. 定位的效率要高。同样要求编写有效的、执行效率高的自动化测试。

## 合理的测试搭配

**什么样的测试能够帮助实现快速定位问题和快速发现问题的两个速度目标呢？**

提到测试种类，袁帅多年的开发经验中也记不清听过很多少测试概念了，比如，单元测试、集成测试、功能测试、端到端测试、客户验收测试、冒烟测试、性能测试、安全性测试、易用性测试，等等。

关于这些测试概念，业界一直众说纷纭，缺乏统一的标准定义。为了更友好地介绍测试搭配，袁帅找到了敏捷测试四象限[1]。

### 测试四象限

![](/images/tdd/testing-quadrants.webp)

敏捷测试四象限，分别从支撑团队和评价产品，面向技术和面向业务四个维度来划分不同的测试：

+ Q1：面向技术和支撑团队，支撑开发团队编码工作，聚焦较细粒度的代码，质量内建的地基
+ Q2：面向业务和支撑团队，支撑开发团队编码工作，聚焦较高层级的业务，质量内建的屋顶
+ Q3：面向业务和评价产品，评价软件产品功能方面，聚焦感性的用户体验，产品口碑的地基
+ Q4：面向技术和评价产品，评价软件产品跨功能方面，聚焦产品的周边特性，产品稳定的保障

四象限提倡：**不同的测试具有不同的目的，可以从团队、产品、业务、技术四个维度出发，制定不同的测试策略来提升软件交付的效能**。

Q1涵盖了支撑团队、面向技术的测试。**用以帮助团队更快速定位问题**，通常这种测试覆盖的代码行数较少，比如单元测试和组件测试。

Q2涵盖了支撑团队、面向业务的测试。**用以帮助团队更快发现问题**，通常这种测试覆盖的代码范围较广，比如面向业务功能的功能测试，更容易发现系统业务功能的问题。

Q3涵盖的是一些需要人主观参与的测试。比如探索性测试、易用性测试和客户验收测试，这些测试一些分析性思考和创造力，通常需要专业的QA来做。它们更多是从业务价值视角去测试软件产品，做一些自动化测试无法做到的事情。

Q4则是从技术视角去评估软件产品，比如安全测试、性能测试等，这些测试通常需要借助一些专业的工具来完成。

因为开发背景，袁帅更多关注在支持团队（Q1 + Q2）的测试上，Q1和Q2通过针对面向业务的粗粒度单元和面向技术的细粒度单元构建自动化测试来帮助发现问题和定位问题，从而缩短发现问题和定位问题的时间。因为同时要满足效率要求，通常不会在真实系统的运行环境中测试。而评价产品（Q3 + Q4）则会把整个系统当作一个整体去看待，既包含了完整的系统组件也包含了运行环境。

### 支持团队的测试

Q1主要关注的是软件内部质量，它包含了细粒度的测试，比如单元测试，虽然不同的项目、不同的人对单元的定义不一样，但有一点共识是它测试的单元很小，比如面向对象中的单个类或函数、或者几个有关系的类或函数、函数式编程中的函数。

另外，在一个分层的Web Service中，单独对Service和Domain的API进行的测试这些属于单元测试，单元测试通常需要测试替身技术来隔离依赖，比如测试Service需要Stub掉Repository，测试Controller提供的API，会使用Stub替换Service和Domain。

组件测试的测试范围稍微会广一些，覆盖的范围更广，比如单个分层系统中各个层级集成在一起测试，并采用Mock技术隔离外部依赖。业界关于组件测试的定义也不统一，袁帅借鉴了老马主页上微服务测试策略[2]对组件测试的定义。另一种比较流行的说法：组件测试的组件指进程内架构中的不同层级的的组件，如Controller、Service、Repository。至于具体指什么，要参考具体团队的上下文共识。

Q2主要关注的是软件的外部质量，它从客户使用的角度去做功能验收测试。比如端到端测试、UI测试都属于这一类测试。这类测试的特点是站在终端业务视角，按照用户故事的AC去验收功能。

功能验收测试成本较高，如果做不好，维护这类测试可能会拖累交付。首先，做功能验收测试需要模拟真实环境，将服务真实运行起来，对于一些外部的不可控的服务，同样也会采用Mock技术。所以，测试环境搭建成本较高，特别是UI这种端到端的测试，因为界面的不稳定性会让UI测试变得脆弱，提升了维护成本。现在一些前后端分离的Web Service软件系统，通常功能验收测试会绕过UI，模拟UI的调用来测试API功能。

Q2中的测试站在更高的业务角度，把控软件的外部质量，更容易发现系统的功能问题，是一种很好的回归测试套件。但它付出的是更大的维护成本，所以需要配置合理的功能验收测试，然后结合Q1细粒度的测试。

由于单元测试、组件测试和集成测试，在业界没有统一的定义，在这里，袁帅把Q1统称为**定位测试**，Q2为**发现测试**。

就拿由Mike Cohn提出的经典测试金字塔，提倡了一种最佳测试平衡，平衡了发现问题和定位问题这两个关键因素。

![](/images/tdd/test-pyramid.webp)

### 测试实例化

为了更好地理解发现问题和定位问题的测试，袁帅编写了一个简单的Web Service。该Service提供了用户登录API。对于用户登录功能进行API功能测试时会模拟发起一个登录API请求，系统接收到请求后做一系列业务处理返回预期的结果。

![](/images/tdd/tdd-api-service.webp)

API功能测试很容易发现功能问题，但是当测试失败时，袁帅很快知道其功能上有问题，但不知道具体问题出在哪里。此时，袁帅进一步把Web Service打开，对内部的不同层和组件进行测试，有API 端口层的Controller组件，业务层Service组件，数据访问层的Repository组件。

![](/images/tdd/tdd-components.webp)

这类测试聚焦更细粒度的组件，更容易定位问题。配合着API功能测试，达到发现问题和定位问题的目的。

在编写细粒度的代码组件测试时，SUT是不同层的组件，SUT的全称是System Under Test，即测试目标。通常它会存在一些依赖，即DOC，全称Depended-on Component。对应到刚才的例子，UserController的DOC是UserService，UserService的DOC是UserRepository，UserRepository的DOC是Database。

![](/images/tdd/tdd-sut-doc.webp)

对内部组件进行测试，需要使用Test Double来替换掉对应的DOC。关于Test Double，袁帅打算写单独的文章来聊聊。

## 写在最后

软件开发，你不可能一开始就把软件做对，亦或者你不可能一直一开始就做对。但发现和定位问题的速度有可能被持续提升。长期来看，提升这两个速度的途径也只有一条 -- 自动化测试，再加上限定词：合理有效。

敏捷测试四象限从四个维度来划分测试类型，帮助你制定合理有效的测试策略。Q1涵盖了支撑团队、面向技术的定位测试，提升定位问题的速度。Q2涵盖了支撑团队、面向业务的测试，提升发现问题的速度，重点关注Q1和Q2。

自动化测试相比于手工测试，也不是免费的午餐，高铁不能跑在普通绿皮车的轨道上，票也贵很多。自动化测试对团队的能力提出了一定的要求，能否做出合适的测试组合，能否选对合适的工具，能否编写有效的测试，这些都是团队要面对的实际挑战，但以目前业界在这方面的成熟度，都算不上什么大碍，只要你愿意用点劲，"高铁票还有可以买的"

## 注释

1. [1]. 敏捷测试象限源自 Brian Marick 最开始提出的敏捷测试矩阵。后来在他的许可下，敏捷测试专家 Lisa Crispin 和 Janet Gregory 做了扩展，并在她们的著作《[敏捷软件测试：测试人员与敏捷团队的实践指南](https://book.douban.com/subject/5338399/)》提出了敏捷测试象限的概念。敏捷测试四象限，不是测试分类规则，更多提供了测试分层的指导原则，建议结合**发现问题**和**定位问题**背后的核心目的去理解它。
2. [2]. 老马主页上的一个Deck《[微服务测试策略](https://martinfowler.com/articles/microservice-testing/#testing-component-in-process-diagram)》，提出了进程内和进程外的组件测试概念。

## 扩展学习

1. [测试大家庭](https://www.yuque.com/yuanshenjian/agile/test-family)
2. [关于敏捷测试象限的"秘密"](https://www.bylinzi.com/2022/05/30/agile-testing-quadrants/)
3. [工程效能管理微课程](https://drive.google.com/file/d/1kQ6CSGLs6BgLGGSs3HSLtwt0hIEtRDGg/view)（TW内部）
